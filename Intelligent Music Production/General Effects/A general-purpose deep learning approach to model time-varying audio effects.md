#2019 [A general-purpose deep learning approach to model time-varying audio effects](http://arxiv.org/abs/1905.06148)
Author: Ramírez, Marco A. Martínez; Benetos, Emmanouil; Reiss, Joshua D.
>Abstract: Audio processors whose parameters are modiﬁed periodically over time are often referred as time-varying or modulation based audio effects. Most existing methods for modeling these type of effect units are often optimized to a very speciﬁc circuit and cannot be efﬁciently generalized to other time-varying effects. Based on convolutional and recurrent neural networks, we propose a deep learning architecture for generic black-box modeling of audio processors with long-term memory. We explore the capabilities of deep neural networks to learn such long temporal dependencies and we show the network modeling various linear and nonlinear, time-varying and time-invariant audio effects. In order to measure the performance of the model, we propose an objective metric based on the psychoacoustics of modulation frequency perception. We also analyze what the model is actually learning and how the given task is accomplished.

Data Set: [IDMT-SMT-AudioEffects dataset](https://www.idmt.fraunhofer.de/en/business_units/m2d/smt/audio_effects.html)

Source Code: [Source Code](https://github.com/lucieperrotta/ASP)

Demo: [Demo](https://mchijmma.github.io/modeling-time-varying/)

