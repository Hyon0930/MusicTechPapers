#  [Automatic Mixing Level Balancing Enhanced Through Source Interference Identiﬁcation](http://www.aes.org/e-lib/browse.cfm?elib=20355)
Author: Moffat, David; Sandler, Mark B

Year: 2019
>Abstract: It has been well established that equal loudness normalisation can produce a perceptually appropriate level balance in an automated mix. Previous work assumes that each captured track represents an individual sound source. In the context of a live drum recording this assumption is incorrect. This paper will demonstrate approach to identify the source interference and adjust the source gains accordingly, to ensure that tracks are all set to equal perceptual loudness. The impact of this interference on the selected gain parameters and resultant mixture is highlighted.

Data Set: [ENST dataset](http://www.tsi.telecom-paristech.fr/aao/en/2010/02/19/enst-drums-an-extensive-audio-visual-database-for-drum-sigls-processing/)

Source Code: Not availabe

Demo: Not availabe

#  [Automated Tonal Balance Enhancement for Audio Mastering Applications](http://www.aes.org/e-lib/browse.cfm?elib=16737)
Author: Mimilakis, Stylianos-Ioannis; Drossos, Konstantinos; Floros, Andreas; Katerelos, Dionysios

Year: 2013
>Abstract: Modern audio mastering procedures are involved with the selective enhancement or attenuation of specific frequency bands. The main reason is the tonal enhancement of the original / unmastered audio material. The aforementioned process is mostly based on the musical information and the mode of the audio material. This information can be retrieved from a listening procedure of the original stimuli, or the corespondent musical key notes. The current work presents an adaptive and automated equalization system that performs the aforementioned mastering procedure, based on a novel method of fundamental frequency tracking. In addition to this, the overall system is being evaluated with objective PEAQ analysis and subjective listening tests in real mastering audio conditions.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [Applications of Loudness Models in Audio Engineering](http://www.open-access.bcu.ac.uk/7228/1/PhD%20Thesis.pdf)
Author: Ward, Dominic

Year: 2017
>Abstract: This thesis investigates the application of perceptual models to areas of audio engineering, with a particular focus on music production. The goal was to establish efficient and practical tools for the measurement and control of the perceived loudness of musical sounds. Two types of loudness model were investigated: the single-band model and the multiband excitation pattern (EP) model. The heuristic single-band devices were designed to be simple but sufficiently effective for real-world application, whereas the multiband procedures were developed to give a reasonable account of a large body of psychoacoustic findings according to a functional model of the peripheral hearing system. The research addresses the extent to which current models of loudness generalise to musical instruments, and whether can they be successfully employed in music applications. The domain-specific disparity between the two types of model was first tackled by reducing the computational load of state-of-the-art EP models to allow for fast but low-error auditory signal processing. Two elaborate hearing models were analysed and optimised using musical instruments and speech as test stimuli. It was shown that, after significantly reducing the complexity of both procedures, estimates of global loudness, such as peak loudness, as well as the intermediate auditory representations can be preserved with high accuracy. Based on the optimisations, two real-time applications were developed: a binaural loudness meter and an automatic multitrack mixer. This second system was designed to work independently of the loudness measurement procedure, and therefore supports both linear and nonlinear models. This allowed for a single mixing device to be assessed using different loudness metrics and this was demonstrated by evaluating three configurations through subjective assessment. Unexpectedly, when asked to rate both the overall quality of a mix and the degree to which instruments were equally loud, listeners preferred mixes generated using heuristic single-band models over those produced using a multiband procedure. A series of more systematic listening tests were conducted to further investigate this finding. Subjective loudness matches of musical instruments commonly found in western popular music were collected to evaluate the performance of five published models. The results were in accord with the application-based assessment, namely that current EP procedures do not generalise well when estimating the relative loudness of musical sounds which have marked differences in spectral content. Model specific issues were identified relating to the calculation of spectral loudness summation (SLS) and the method used to determine the global-loudness percept of time-varying musical sounds; associated refinements were proposed. It was shown that a new multiband loudness model with a heuristic loudness transformation yields superior performance over existing methods. This supports the idea that a revised model of SLS is needed, and therefore that modification to this stage in existing psychoacoustic procedures is an essential step towards the goal of achieving real-world deployment.

Data Set: [Sound Quality Assessment Material](https://sound.media.mit.edu/resources/mpeg4/audio/sqam/)

Source Code: Not availabe

Demo: Not availabe

#  [The Effect of Loudness Overflow on Equal- Loudness-Level Contours](http://www.aes.org/e-lib/browse.cfm?elib=15834)
Author: Simpson, Andrew J R; Reiss, Joshua D

Year: 2011
>Abstract: This paper presents a formal derivation of the Loudness Overflow Effect (LOE), which describes the impact of nonlinear distortion on loudness. Computational analysis is then performed, comprised of two experiments involving two compressive static nonlinearities, and using two well-known time-varying loudness models. The results characterize the nonlinearities in terms of LOE as a function of frequency and of listening level in the case of 250ms pure-tone stimuli, and in terms of the traditional equal-loudness-level contours. The analysis is then extended to synthesized wind instruments for one of the nonlinearities. The effect of the nonlinearity on loudness as a function of musical note fundamental frequency and listening level is described for various synthesized instruments.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [Algorithms to measure audio programme loudness and true-peak audio level](https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1770-4-201510-I!!PDF-E.pdf)
Author: 

Year: 2015
>Abstract: 

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [Multi-track mixing using a model of loudness and partial loudness](http://www.aes.org/e-lib/browse.cfm?elib=16436)
Author: Ward, Dominic; Reiss, Joshua D; Athwal, Cham

Year: 2012
>Abstract: A method for generating a mix of multi-track recordings using an auditory model has been developed. The proposed method is based on the concept that a balanced mix is one in which the loudness of all instruments are equal. A sophisticated psychoacoustic loudness model is used to measure the loudness of each track both in quiet and when mixed with any combination of the remaining tracks. Such measures are used to control the track gains in a time-varying manner. Finally we demonstrate how model predictions of partial loudness can be used to counteract energetic masking for any track, allowing the user to achieve better channel intelligibility in complex music mixtures.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [Automatic gain and fader control for live mixing](http://ieeexplore.ieee.org/document/5346498/)
Author: Perez-Gonzalez, Enrique; Reiss, Joshua

Year: 2009
>Abstract: A cross-adaptive mixing device has been developed for the purpose of optimizing the gain levels of a live audio mixture. The method aims to achieve optimal mixing levels by optimizing the ratios between the loudness of each individual input channel and the overall loudness contained in a stereo mix. In order to evaluate the amount of loudness of each channel in real-time, accumulative statistical measurements were performed. The system uses a cross-adaptive algorithm to map the loudness indicators to the channel gain values. The system has applications in automatic mixing of live music, live mixing of game audio, and studio recording post-production.

Data Set: Not availabe

Source Code: Not availabe

Demo: [Demo](http://www.elec.qmul.ac.uk/digitalmusic/automaticmixin)

#  [The Mathematics of Mixing](http://www.aes.org/e-lib/browse.cfm?elib=17081)
Author: Terrell,, Michael; Simpson, Andrew; Sandler, Mark

Year: 2014
>Abstract: Mixing is a quintessential optimization problem. Given control of several component tracks, a balance must be struck that reflects a trade-off between engineering methods, artistic objectives, and auditory perceptual constraints. Formally, this balance can be thought of as the optimal solution to a system of mathematical equations that describe the relationships between the component tracks within a mix. Hence, the nature of these equations defines the process by which solutions may be arrived at. As perception is strongly nonlinear, an analytical solution to this set of equations is not possible and so a search must be conducted. Here, taking loudness as an example, we develop an optimization theory treatment of the problem of mixing, complete with case studies to illustrate how auditory perception can complicate the process, not least due to masking-related interactions.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [ESTIMATING THE LOUDNESS BALANCE OF MUSICAL MIXTURES USING AUDIO SOURCE SEPARATION](https://pdfs.semanticscholar.org/2810/4e5ab0375cb95d866112002952489b291742.pdf)
Author: Ward, Dominic; Wierstorf, Hagen; Mason, Russell D; Plumbley, Mark D; Hummersone, Chris

Year: 2017
>Abstract: To assist with the development of intelligent mixing systems, it would be useful to be able to extract the loudness balance of sources in an existing musical mixture. The relative-to-mix loudness level of four instrument groups was predicted using the sources extracted by 12 audio source separation algorithms. The predictions were compared with the ground truth loudness data of the original unmixed stems obtained from a recent dataset involving 100 mixed songs. It was found that the best source separation system could predict the relative loudness of each instrument group with an average root-mean-square error of 1.2 LU, with superior performance obtained on vocals.

Data Set: [DSD100](https://sigsep.github.io/datasets/dsd100.html)

Source Code: [Source Code](https://code.soundsoftware.ac.uk/hg/wimp17-ward-et-al)

Demo: Not availabe

#  [LOUDNESS ALGORITHMS FOR AUTOMATIC MIXING](https://pdfs.semanticscholar.org/75c8/bdb6432ee547d3a167badaa128151c242366.pdf)
Author: Ward, Dominic; Reiss, Joshua D

Year: 2016
>Abstract: Accurate loudness measurement is imperative for intelligent music mixing systems, where one of the most fundamental tasks is to automate the fader balance. The goal of this short paper is to highlight state-of-the-art loudness algorithms to the automatic mixing community, and give insight into their differences when applied to multi-track audio.

Data Set: Not availabe

Source Code: [Source Code](https://code.soundsoftware.ac.uk/hg/wimp16-ward-reiss)

Demo: Not availabe

#  [An automatic maximum gain normalization technique with applications to audio mixing.](http://www.aes.org/e-lib/browse.cfm?elib=14541)
Author: Gonzalez, Enrique Perez; Reiss, Joshua

Year: 2008
>Abstract: A method for real-time magnitude gain normalization of a changing linear system has been developed and tested with a parametric filter design. The method is useful in situations where the maximum gain before feedback is needed. The method automatically calculates the appropriate gain that should be applied in order to maintain maximum unitary gain. The method uses an impulse measurement of a mathematical model of the system to be normalized. This is particularly useful for mixing engineers, who have to continually revise their gain structure in order to maximize gain before feedback. The system is also useful in many other situations where solving the analytical solution from the mathematical model is not possible.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [IMPLEMENTATION AND EVALUATION OF DYNAMIC LEVEL OF AUDIO DETAIL](https://www.eecs.qmul.ac.uk/~josh/documents/2015/Durr%20et%20al%20-%20AES56%20-%202015.pdf)
Author: Durr, Gabriel; Peixoto, Lys; Souza, Marcelo; Tanoue, Raisa; Reiss, Joshua D

Year: 2015
>Abstract: Sound synthesis involves creating a desired sound using software or algorithms and analysing the digital signal processing involved in the creation of the sound, rather than recording it. However, synthesis techniques are often too computationally complex for use in many scenarios. This project aims to implement and assess sound synthesis models with dynamic Level of Audio Detail (LOAD). The manipulations consist of modifying existing models to achieve a more or less complex implementation while still retaining the perceptual characteristics of the sound. The models implemented consist of sine waves, noise sources and filters that reproduce the desired sound, which could then be enhanced or reduced to provide dynamic LOAD. These different levels were then analysed in the time-frequency domain, and computational time and floating point operations were assessed as a function of the LOAD.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [Implementation and Evaluation of Autonomous Multi-track Fader Control](http://www.aes.org/e-lib/browse.cfm?elib=16226)
Author: Dukes, Bob

Year: 2012
>Abstract: A new approach to the autonomous control of faders for multi-track audio mixing is presented. The algorithm is designed to generate an automatic sound mix from an arbitrary number of monaural or stereo audio tracks of any sample rate, and to be suitable for both live and post-production use. Mixing levels are determined by the use of the EBU R-128 loudness measure, with a cross-adaptive process to bring each track to a time-varying average. A hysteresis loudness gate and selective smoothing prevents the adjustment of intentional dynamics in the music. Realtime and off-line software implementations have been created. Subjective evaluation is provided in the form of listening tests, where the method is compared against the results of a human mix and a previous automatic fader implementation.

Data Set: Not availabe

Source Code: Not availabe

Demo: Not availabe

#  [Comparison of Loudness Features for Automatic Level Adjustment in Mixing](http://www.aes.org/e-lib/browse.cfm?elib=17928)
Author: Wichern, Gordon; Wishnick, Aaron S; Lukin, Alexey; Robertson, Hannah

Year: 2015
>Abstract: Manually setting the level of each track of a multitrack recording is often the ﬁrst step in the mixing process. In order to automate this process, loudness features are computed for each track and gains are algorithmically adjusted to achieve target loudness values. In this paper we ﬁrst examine human mixes from a multitrack dataset to determine instrument-dependent target loudness templates. We then use these templates to develop three diﬀerent automatic level-based mixing algorithms. The ﬁrst is based on a simple energy-based loudness model, the second uses a more sophisticated psychoacoustic model, and the third incorporates masking eﬀects into the psychoacoustic model. The three automatic mixing approaches are compared to human mixes using a subjective listening test. Results show that subjects preferred the automatic mixes created from the simple energy-based model, indicating that the complex psychoacoustic model may not be necessary in an automated level setting application.

Data Set: [MedleyDB](https://medleydb.weebly.com/)

Source Code: Not availabe

Demo: Not availabe

